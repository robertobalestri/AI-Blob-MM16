#The program was tested via Azure OpenaAI Api, but it can be easily adapted to other LLM providers modifying the code in the following file:
#/src/ai_models.py

AZURE_OPENAI_API_KEY = '---'
OPENAI_API_KEY = '---'
OPENAI_API_TYPE = 'azure'

AZURE_OPENAI_API_ENDPOINT = '---'
AZURE_OPENAI_API_VERSION = "2024-08-01-preview"
AZURE_OPENAI_LLM_DEPLOYMENT_NAME_INTELLIGENT = "gpt-4o"
AZURE_OPENAI_LLM_MODEL_NAME_INTELLIGENT = "gpt-4o"
AZURE_OPENAI_LLM_DEPLOYMENT_NAME_CHEAP = "gpt-4o-mini"
AZURE_OPENAI_LLM_MODEL_NAME_CHEAP = "gpt-4o-mini"

AZURE_COHERE_EMBEDDING_API_KEY = "---"
AZURE_COHERE_EMBEDDING_API_ENDPOINT = "---"
AZURE_COHERE_EMBEDDING_MODEL_NAME = "Cohere-embed-v3-multilingual"

# Model Configuration
WHISPER_MODEL=large-v3
DEVICE=cuda
COMPUTE_TYPE=float16
NUM_WORKERS = 4

# Vector Store Configuration
VECTOR_STORE_DIR=vector_store
VECTOR_STORE_COLLECTION=transcripts

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

MOCK_LLM_CALL_IN_LAST_STEP = "True" #LEAVE THIS ALWAYS TO TRUE, IT HASN'T BEEN TESTED VERY WELL THE OTHER BEHAVIOUR



THEME = "L'uomo, le macchine, le morti sul lavoro"
SEED = "5_con_nuovo_meccanismo_batching"
TOP_IRONY_LIMIT = 10
TOP_RELEVANCE_LIMIT = 15
